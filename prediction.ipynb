{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsL7lJshIcYG"
      },
      "source": [
        "# Prediction\n",
        "附上test data的連結\n",
        "[link!](https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sokidISEIcYK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_0hvxKM4IcYM"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.preprocessing.image as tfimage\n",
        "\n",
        "def load_datasets(path):\n",
        "  clean = []\n",
        "  types = []\n",
        "  label = []\n",
        "\n",
        "  # loop over every folder\n",
        "  i = -1\n",
        "  k = 0\n",
        "  for folder in os.listdir(path):\n",
        "    i += 1\n",
        "    label.append(folder)\n",
        "    print(i, \": \", folder)\n",
        "    for file in os.listdir(path + '/' + folder):\n",
        "        # image = tfimage.load_img(path + '/' + folder + '/' + file, target_size=(256,256))\n",
        "        # image = tfimage.img_to_array(image).astype('float32') / 255\n",
        "        img = tfimage.load_img(path + '/' + folder + '/' + file)\n",
        "        img = cv2.imread(os.path.join(path,folder,file),cv2.IMREAD_GRAYSCALE) # Convert to Image to Grayscale bc contour\n",
        "        img=~img # Invert the bits of image 255 -> 0 / test the dataset\n",
        "        if img is not None:\n",
        "          ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY) # THRESH_BINARY: Set bits > 127 to 1(white background) and <= 127 to 0(black) \n",
        "          ctrs, ret = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # determine object boundary, remove background\n",
        "          cnt=sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
        "          w=int(45)\n",
        "          h=int(45)\n",
        "          # maximum area of the rectangle\n",
        "          maxi=0\n",
        "          for c in cnt: # traverse in all the rectangles we have\n",
        "            x,y,w,h=cv2.boundingRect(c)\n",
        "            maxi=max(w*h,maxi)\n",
        "            if maxi==w*h:\n",
        "              x_max=x\n",
        "              y_max=y\n",
        "              w_max=w\n",
        "              h_max=h\n",
        "          im_crop= thresh[y_max:y_max+h_max+10, x_max:x_max+w_max+10] # add 10 extra margin to avoid error\n",
        "          im_resize = cv2.resize(im_crop,(45,45))\n",
        "          im_resize =  tfimage.img_to_array(im_resize).astype('float32') / 255\n",
        "          #im_resize=np.reshape(im_resize,(784,1)) #resize to (28,28)\n",
        "          clean.append(im_resize) # flat the matrix\n",
        "          types.append(i)\n",
        "\n",
        "  types = tf.one_hot(types, depth=i+1)\n",
        "  types = np.array(types)\n",
        "  clean = np.array(clean)\n",
        "\n",
        "  print(\"image shape: \", clean.shape)\n",
        "  print(\"label shape: \", types.shape)\n",
        "  \n",
        "  return types, clean, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZGntgD_IcYN"
      },
      "source": [
        "**load model and test data (for prediction)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6k7htQU2IcYO",
        "outputId": "d6bde5e0-1c72-4ad0-9294-4269ba805e04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 :  !\n",
            "1 :  +\n",
            "2 :  -\n",
            "3 :  0\n",
            "4 :  1\n",
            "5 :  2\n",
            "6 :  3\n",
            "7 :  4\n",
            "8 :  5\n",
            "9 :  6\n",
            "10 :  7\n",
            "11 :  8\n",
            "12 :  9\n",
            "13 :  cos\n",
            "14 :  div\n",
            "15 :  log\n",
            "16 :  pi\n",
            "17 :  sin\n",
            "18 :  tan\n",
            "19 :  x\n",
            "image shape:  (172847, 45, 45, 1)\n",
            "label shape:  (172847, 20)\n"
          ]
        }
      ],
      "source": [
        "modelpath = \"C:\\\\Users\\\\USER\\\\Desktop\\\\MathHelper\\\\little_helper.h5\"\n",
        "classifier = tf.keras.models.load_model(modelpath)\n",
        "datapath = \"C:\\\\Users\\\\USER\\\\Desktop\\\\MathHelper\\\\dataset\"\n",
        "types, clean, label = load_datasets(datapath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaFPKghpIcYQ"
      },
      "source": [
        "**prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4CPr8mI1IcYQ",
        "outputId": "b92807ca-5313-4c10-c45e-a2622443eb25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8520/8520 - 25s - loss: 0.0930 - accuracy: 0.9759\n",
            "test loss:  0.09300395101308823\n",
            "test accuracy:  0.9759091734886169\n"
          ]
        }
      ],
      "source": [
        "class_num = 20\n",
        "scores = classifier.evaluate(\n",
        "        x = clean,\n",
        "        y = types,\n",
        "        batch_size = 64,\n",
        "        verbose = 2)\n",
        "\n",
        "print(\"test loss: \", scores[0])\n",
        "print(\"test accuracy: \", scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QKzu6hZUIcYR"
      },
      "outputs": [],
      "source": [
        "# for visualize\n",
        "results = classifier.predict(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Odb3mEOrIcYS"
      },
      "outputs": [],
      "source": [
        "total = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "wrong = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "for i in range(clean.shape[0]):\n",
        "    answer = np.where(results[i] == np.max(results[i]))[0][0]\n",
        "    reality = np.where(types[i] == 1)[0][0]\n",
        "    total[reality] += 1\n",
        "    if (answer != reality):\n",
        "        wrong[reality] += 1\n",
        "\n",
        "wrong_rate = [round(int(w) / int(t) * 100, 2) for w, t in zip(wrong, total)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VMK0mFD2IcYT",
        "outputId": "72004ca0-9794-4a9d-e413-62397b220ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   label  wrong rate (%)\n",
            "0      !           19.38\n",
            "1      +            1.42\n",
            "2      -            0.19\n",
            "3      0            1.50\n",
            "4      1            0.97\n",
            "5      2            1.68\n",
            "6      3            0.57\n",
            "7      4            1.69\n",
            "8      5            5.08\n",
            "9      6            2.85\n",
            "10     7            7.84\n",
            "11     8            1.24\n",
            "12     9            8.38\n",
            "13   cos            8.37\n",
            "14   div           88.48\n",
            "15   log            0.70\n",
            "16    pi           19.13\n",
            "17   sin            2.31\n",
            "18     x            0.65\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd  \n",
        "\n",
        "data = {'label': label, 'wrong rate (%)': wrong_rate}  \n",
        "df = pd.DataFrame(data)  \n",
        "\n",
        "print(df)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CJBJywF7IcYU",
        "outputId": "1274a232-33a7-48de-9525-cc3991521714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VISUALIZE-PREDICTED-RESULT---------------------------\n",
            "! 0.0 %\n",
            "+ 0.011 %\n",
            "- 0.681 %\n",
            "0 3.651 %\n",
            "1 4.43 %\n",
            "2 31.549 %\n",
            "3 3.525 %\n",
            "4 0.547 %\n",
            "5 0.94 %\n",
            "6 0.025 %\n",
            "7 0.501 %\n",
            "8 0.624 %\n",
            "9 51.243 %\n",
            "predict:  9\n",
            "reality:  5\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "tmp = np.random.randint(0, len(clean))\n",
        "answer = np.where(results[tmp] == np.max(results[tmp]))[0][0]\n",
        "reality = np.where(types[tmp] == 1)[0][0]\n",
        "\n",
        "print(\"VISUALIZE-PREDICTED-RESULT---------------------------\")\n",
        "for p in range(class_num):\n",
        "    print(label[p], round(results[tmp][p]*100, 3), '%')\n",
        "\n",
        "print(\"predict: \", label[answer])\n",
        "print(\"reality: \", label[reality])\n",
        "plt.imshow(clean[tmp])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "prediction.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
