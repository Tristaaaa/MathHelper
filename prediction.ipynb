{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsL7lJshIcYG"
      },
      "source": [
        "# Prediction\n",
        "附上test data的連結\n",
        "[link!](https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sokidISEIcYK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_0hvxKM4IcYM"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.preprocessing.image as tfimage\n",
        "\n",
        "def load_datasets(path):\n",
        "  clean = []\n",
        "  types = []\n",
        "  label = []\n",
        "\n",
        "  # loop over every folder\n",
        "  i = -1\n",
        "  k = 0\n",
        "  for folder in os.listdir(path):\n",
        "    i += 1\n",
        "    label.append(folder)\n",
        "    print(i, \": \", folder)\n",
        "    for file in os.listdir(path + '/' + folder):\n",
        "        # image = tfimage.load_img(path + '/' + folder + '/' + file, target_size=(256,256))\n",
        "        # image = tfimage.img_to_array(image).astype('float32') / 255\n",
        "        img = tfimage.load_img(path + '/' + folder + '/' + file)\n",
        "        img = cv2.imread(os.path.join(path,folder,file),cv2.IMREAD_GRAYSCALE) # Convert to Image to Grayscale bc contour\n",
        "        img=~img # Invert the bits of image 255 -> 0 / test the dataset\n",
        "        if img is not None:\n",
        "          ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY) # THRESH_BINARY: Set bits > 127 to 1(white background) and <= 127 to 0(black) \n",
        "          ctrs, ret = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # determine object boundary, remove background\n",
        "          cnt=sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
        "          w=int(28)\n",
        "          h=int(28)\n",
        "          # maximum area of the rectangle\n",
        "          maxi=0\n",
        "          for c in cnt: # traverse in all the rectangles we have\n",
        "            x,y,w,h=cv2.boundingRect(c)\n",
        "            maxi=max(w*h,maxi)\n",
        "            if maxi==w*h:\n",
        "              x_max=x\n",
        "              y_max=y\n",
        "              w_max=w\n",
        "              h_max=h\n",
        "          im_crop= thresh[y_max:y_max+h_max+10, x_max:x_max+w_max+10] # add 10 extra margin to avoid error\n",
        "          im_resize = cv2.resize(im_crop,(28,28))\n",
        "          im_resize =  tfimage.img_to_array(im_resize).astype('float32') / 255\n",
        "          #im_resize=np.reshape(im_resize,(784,1)) #resize to (28,28)\n",
        "          clean.append(im_resize) # flat the matrix\n",
        "          types.append(i)\n",
        "\n",
        "  types = tf.one_hot(types, depth=i+1)\n",
        "  types = np.array(types)\n",
        "  clean = np.array(clean)\n",
        "\n",
        "  print(\"image shape: \", clean.shape)\n",
        "  print(\"label shape: \", types.shape)\n",
        "  \n",
        "  return types, clean, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZGntgD_IcYN"
      },
      "source": [
        "**load model and test data (for prediction)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6k7htQU2IcYO",
        "outputId": "d6bde5e0-1c72-4ad0-9294-4269ba805e04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 :  +\n",
            "1 :  -\n",
            "2 :  0\n",
            "3 :  1\n",
            "4 :  2\n",
            "5 :  3\n",
            "6 :  4\n",
            "7 :  5\n",
            "8 :  6\n",
            "9 :  7\n",
            "10 :  8\n",
            "11 :  9\n",
            "12 :  x\n",
            "image shape:  (156617, 28, 28, 1)\n",
            "label shape:  (156617, 13)\n"
          ]
        }
      ],
      "source": [
        "modelpath = \"C:\\\\Users\\\\USER\\\\Desktop\\\\MathHelper\\\\little_helper.h5\"\n",
        "classifier = tf.keras.models.load_model(modelpath)\n",
        "datapath = \"C:\\\\Users\\\\USER\\\\Desktop\\\\MathHelper\\\\dataset\"\n",
        "types, clean, label = load_datasets(datapath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaFPKghpIcYQ"
      },
      "source": [
        "**prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4CPr8mI1IcYQ",
        "outputId": "b92807ca-5313-4c10-c45e-a2622443eb25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7831/7831 - 32s - loss: 0.0148 - accuracy: 0.9961\n",
            "test loss:  0.014767018146812916\n",
            "test accuracy:  0.9960604310035706\n"
          ]
        }
      ],
      "source": [
        "class_num = 13\n",
        "scores = classifier.evaluate(\n",
        "        x = clean,\n",
        "        y = types,\n",
        "        batch_size = 20,\n",
        "        verbose = 2)\n",
        "\n",
        "print(\"test loss: \", scores[0])\n",
        "print(\"test accuracy: \", scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QKzu6hZUIcYR"
      },
      "outputs": [],
      "source": [
        "# for visualize\n",
        "results = classifier.predict(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Odb3mEOrIcYS"
      },
      "outputs": [],
      "source": [
        "total = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "wrong = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "for i in range(clean.shape[0]):\n",
        "    answer = np.where(results[i] == np.max(results[i]))[0][0]\n",
        "    reality = np.where(types[i] == 1)[0][0]\n",
        "    total[reality] += 1\n",
        "    if (answer != reality):\n",
        "        wrong[reality] += 1\n",
        "\n",
        "wrong_rate = [round(int(w) / int(t) * 100, 2) for w, t in zip(wrong, total)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VMK0mFD2IcYT",
        "outputId": "72004ca0-9794-4a9d-e413-62397b220ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   label  total  wrong rate (%)\n",
            "0      +  25112            0.29\n",
            "1      -  33997            0.07\n",
            "2      0   6914            0.22\n",
            "3      1  26520            0.51\n",
            "4      2  26141            0.05\n",
            "5      3  10909            0.52\n",
            "6      4   7396            0.54\n",
            "7      5   3545            0.68\n",
            "8      6   3118            0.38\n",
            "9      7   2909            4.95\n",
            "10     8   3068            2.15\n",
            "11     9   3737            0.32\n",
            "12     x   3251            0.12\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd  \n",
        "\n",
        "data = {'label': label, 'total': total, 'wrong rate (%)': wrong_rate}  \n",
        "df = pd.DataFrame(data)  \n",
        "\n",
        "print(df)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CJBJywF7IcYU",
        "outputId": "1274a232-33a7-48de-9525-cc3991521714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VISUALIZE-PREDICTED-RESULT---------------------------\n",
            "+ 0.0 %\n",
            "- 0.0 %\n",
            "0 0.0 %\n",
            "1 0.0 %\n",
            "2 0.0 %\n",
            "3 0.0 %\n",
            "4 0.0 %\n",
            "5 100.0 %\n",
            "6 0.0 %\n",
            "7 0.0 %\n",
            "8 0.0 %\n",
            "9 0.0 %\n",
            "x 0.0 %\n",
            "predict:  5\n",
            "reality:  5\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "tmp = np.random.randint(0, len(clean))\n",
        "answer = np.where(results[tmp] == np.max(results[tmp]))[0][0]\n",
        "reality = np.where(types[tmp] == 1)[0][0]\n",
        "\n",
        "print(\"VISUALIZE-PREDICTED-RESULT---------------------------\")\n",
        "for p in range(class_num):\n",
        "    print(label[p], round(results[tmp][p]*100, 3), '%')\n",
        "\n",
        "print(\"predict: \", label[answer])\n",
        "print(\"reality: \", label[reality])\n",
        "plt.imshow(clean[tmp])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "prediction.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
